{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.1 Generate validation and test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import natsort\n",
    "import random\n",
    "\n",
    "# Random sampling, generate validation and test sets.\n",
    "def random_sample(num_class, val_rate, test_rate):\n",
    "    train_dir_sub = f'./data/train/subtomogram_mrc'\n",
    "    val_dir_sub = f'./data/val/subtomogram_mrc'\n",
    "    test_dir_sub = f'./data/test/subtomogram_mrc'\n",
    "    train_dir_json = f'./data/train/json_label'\n",
    "    val_dir_json = f'./data/val/json_label'\n",
    "    test_dir_json = f'./data/test/json_label'\n",
    "    if not os.path.exists(val_dir_sub):\n",
    "        os.makedirs(val_dir_sub, exist_ok=True)\n",
    "    if not os.path.exists(val_dir_json):\n",
    "        os.makedirs(val_dir_json, exist_ok=True)\n",
    "    if not os.path.exists(test_dir_sub):\n",
    "        os.makedirs(test_dir_sub, exist_ok=True)\n",
    "    if not os.path.exists(test_dir_json):\n",
    "        os.makedirs(test_dir_json, exist_ok=True)\n",
    "    all_files = os.listdir(train_dir_sub)\n",
    "    sorted_files = natsort.natsorted(all_files)\n",
    "    # print(sorted_files)\n",
    "    for i in range(10):\n",
    "        # print(sorted_files[i*500:(i+1)*500])\n",
    "        one_class_files = sorted_files[i * num_class:(i + 1) * num_class]\n",
    "        val_files = random.sample(one_class_files, int(num_class * val_rate))\n",
    "        one_class_files_rest = [x for x in one_class_files if x not in val_files]\n",
    "        test_files = random.sample(one_class_files_rest, int(num_class * test_rate))\n",
    "        # if i == 1: print(val_files)\n",
    "        for val_file in val_files:\n",
    "            val_file_json = val_file.replace('tomotarget', 'target').replace('mrc', 'json')\n",
    "            source_path_sub = os.path.join(train_dir_sub, val_file)\n",
    "            source_path_json = os.path.join(train_dir_json, val_file_json)\n",
    "            destination_path_sub = os.path.join(val_dir_sub, val_file)\n",
    "            destination_path_json = os.path.join(val_dir_json, val_file_json)\n",
    "            shutil.move(source_path_sub, destination_path_sub)\n",
    "            shutil.move(source_path_json, destination_path_json)\n",
    "\n",
    "        for test_file in test_files:\n",
    "            test_file_json = test_file.replace('tomotarget', 'target').replace('mrc', 'json')\n",
    "            source_path_sub = os.path.join(train_dir_sub, test_file)\n",
    "            source_path_json = os.path.join(train_dir_json, test_file_json)\n",
    "            destination_path_sub = os.path.join(test_dir_sub, test_file)\n",
    "            destination_path_json = os.path.join(test_dir_json, test_file_json)\n",
    "            shutil.move(source_path_sub, destination_path_sub)\n",
    "            shutil.move(source_path_json, destination_path_json)\n",
    "\n",
    "        print(f'class {i} is done')\n",
    "\n",
    "num_class = 500  # the number of each class\n",
    "val_rate = 0.2 # the rate of val\n",
    "test_rate = 0.1 # the rate of test\n",
    "random_sample(num_class, val_rate, test_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.2 Data Transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# https://github.com/Shadowalker1995/MOCO-Subtomograms/blob/master/CustomTransforms.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image_tensor = torch.Tensor(image.copy())\n",
    "        return image_tensor\n",
    "\n",
    "\n",
    "class Normalize3D(object):\n",
    "    \"\"\"Normalize a tensor voxel with mean and standard deviation.\n",
    "    Given mean: ``(mean[1],...,mean[n])`` and std: ``(std[1],..,std[n])`` for ``n``\n",
    "    channels, this transform will normalize each channel of the input\n",
    "    ``torch.*Tensor`` i.e.,\n",
    "    ``output[channel] = (input[channel] - mean[channel]) / std[channel]``\n",
    "\n",
    "    .. note::\n",
    "        This transform acts out of place, i.e., it does not mutate the input tensor.\n",
    "\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for each channel.\n",
    "        std (sequence): Sequence of standard deviations for each channel.\n",
    "        inplace(bool,optional): Bool to make this operation in-place.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std, inplace=False):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor voxel of size (C, D, H, W) to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Normalized Tensor voxel.\n",
    "        \"\"\"\n",
    "        return normalize3D(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "\n",
    "def normalize3D(tensor, mean, std, inplace=False):\n",
    "    \"\"\"Normalize a tensor voxel with mean and standard deviation.\n",
    "\n",
    "    .. note::\n",
    "        This transform acts out of place by default, i.e., it does not mutates the input tensor.\n",
    "\n",
    "    Args:\n",
    "        tensor (Tensor): Tensor voxel of size (C, D, H, W) to be normalized.\n",
    "        mean (sequence): Sequence of means for each channel.\n",
    "        std (sequence): Sequence of standard deviations for each channel.\n",
    "        inplace(bool,optional): Bool to make this operation inplace.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Normalized Tensor voxel.\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(tensor):\n",
    "        raise TypeError('tensor should be a torch tensor. Got {}.'.format(type(tensor)))\n",
    "\n",
    "    if tensor.ndimension() != 4:\n",
    "        raise ValueError('Expected tensor to be a tensor voxel of size (C, D, H, W). Got tensor.size() = '\n",
    "                         '{}.'.format(tensor.size()))\n",
    "\n",
    "    if not inplace:\n",
    "        tensor = tensor.clone()\n",
    "\n",
    "    dtype = tensor.dtype\n",
    "    mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)\n",
    "    std = torch.as_tensor(std, dtype=dtype, device=tensor.device)\n",
    "    if (std == 0).any():\n",
    "        raise ValueError('std evaluated to zero after conversion to {}, leading to division by zero.'.format(dtype))\n",
    "    if mean.ndim == 1:\n",
    "        mean = mean[:, None, None, None]\n",
    "    if std.ndim == 1:\n",
    "        std = std[:, None, None, None]\n",
    "    tensor.sub_(mean).div_(std)\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:02:59.924145Z",
     "start_time": "2024-03-14T05:02:58.860553Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.3 Data load"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Class labels, if using a custom dataset, please customize the class labels.\n",
    "class_10 = [\n",
    "    \"1bxn\",\n",
    "    \"1f1b\",\n",
    "    \"1yg6\",\n",
    "    \"2byu\",\n",
    "    \"2h12\",\n",
    "    \"2ldb\",\n",
    "    \"3gl1\",\n",
    "    \"3hhb\",\n",
    "    \"4d4r\",\n",
    "    \"6t3e\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:03:50.023113Z",
     "start_time": "2024-03-14T05:03:50.019703Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://github.com/Shadowalker1995/MOCO-Subtomograms/blob/master/Custom_CryoET_DataLoader.py\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import natsort\n",
    "import mrcfile\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "def mapping_types(num_classes):\n",
    "    if num_classes == 10:\n",
    "        labels = class_10\n",
    "    # elif num_classes == **:\n",
    "    #     labels = ***\n",
    "\n",
    "    label_to_target = {label: idx for idx, label in enumerate(labels)}\n",
    "    return label_to_target\n",
    "\n",
    "# Dataset\n",
    "class CryoETDatasetLoader(Dataset):\n",
    "    def __init__(self, root_dir, json_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.json_dir = json_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(root_dir)\n",
    "        all_jsons = os.listdir(json_dir)\n",
    "        self.total_imgs = natsort.natsorted(all_imgs)\n",
    "        self.total_jsons = natsort.natsorted(all_jsons)\n",
    "        print(f'{len(self.total_imgs)}, vs {len(self.total_jsons)}')\n",
    "        assert (len(self.total_imgs) == len(self.total_jsons))\n",
    "        num_classes = 10\n",
    "        self.label_to_target = mapping_types(num_classes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_jsons)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_img = os.path.join(self.root_dir, self.total_imgs[idx])\n",
    "        path_json = os.path.join(self.json_dir, self.total_jsons[idx])\n",
    "\n",
    "        with mrcfile.open(path_img, mode='r+', permissive=True) as mrc:\n",
    "            mrc_img = mrc.data\n",
    "            if mrc_img is None:\n",
    "                print(path_img)\n",
    "            try:\n",
    "                mrc_img = mrc_img.astype(np.float32).transpose((2, 1, 0)).reshape((1, 32, 32, 32))\n",
    "            except:\n",
    "                print(mrc_img.shape)\n",
    "                print(path_img)\n",
    "\n",
    "        with open(path_json) as f:\n",
    "            mrc_json = json.load(f)\n",
    "\n",
    "        target = self.label_to_target[mrc_json['name']]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed_mrc_img = self.transform(mrc_img)\n",
    "        else:\n",
    "            transformed_mrc_img = mrc_img\n",
    "\n",
    "        return transformed_mrc_img, target\n",
    "\n",
    "# data path\n",
    "traindir = os.path.join('data', 'train/subtomogram_mrc')\n",
    "traindir_json = os.path.join('data', 'train/json_label')\n",
    "valdir = os.path.join('data', 'val/subtomogram_mrc')\n",
    "valdir_json = os.path.join('data', 'val/json_label')\n",
    "testdir = os.path.join('data', 'test/subtomogram_mrc')\n",
    "testdir_json = os.path.join('data', 'test/json_label')\n",
    "batch_size = 32\n",
    "workers = 4\n",
    "\n",
    "# Initialize normalize\n",
    "stage_normalize_val = Normalize3D(mean=[0.04725085], std=[13.48426468])\n",
    "stage_normalize_train = Normalize3D(mean=[0.05964008], std=[13.57436941])\n",
    "\n",
    "# data augmentation\n",
    "augmentation_train = [\n",
    "    ToTensor(),\n",
    "    stage_normalize_train,\n",
    "]\n",
    "\n",
    "augmentation_val = [\n",
    "    ToTensor(),\n",
    "    stage_normalize_val,\n",
    "]\n",
    "\n",
    "# data load\n",
    "train_dataset = CryoETDatasetLoader(\n",
    "    root_dir=traindir, json_dir=traindir_json,\n",
    "    transform=transforms.Compose(augmentation_train))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "val_dataset = CryoETDatasetLoader(\n",
    "    root_dir=valdir, json_dir=valdir_json,\n",
    "    transform=transforms.Compose(augmentation_val))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True)\n",
    "\n",
    "test_dataset = CryoETDatasetLoader(\n",
    "    root_dir=testdir, json_dir=testdir_json,\n",
    "    transform=transforms.Compose(augmentation_val))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.1 Model Definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# https://github.com/Shadowalker1995/MOCO-Subtomograms/tree/master/Encoder3D\n",
    "# RB3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(32, 16, kernel_size=3, stride=1,\n",
    "                               padding=1)\n",
    "        self.conv2 = nn.Conv3d(32, 16, kernel_size=1, stride=1,\n",
    "                               padding=0)\n",
    "        self.conv3 = nn.Conv3d(16, 32, kernel_size=3, stride=1,\n",
    "                               padding=1)\n",
    "        self.conv4 = nn.Conv3d(32, 16, kernel_size=1, stride=1,\n",
    "                               padding=0)\n",
    "        # self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 32 x 16 x 16 x 16 -> 16 x 16 x 16 x 16\n",
    "        out_R = self.conv1(x)\n",
    "        out_R = self.relu(out_R)\n",
    "        # 32 x 16 x 16 x 16 -> 16 x 16 x 16 x 16\n",
    "        out_L = self.conv2(x)\n",
    "        out_L = self.relu(out_L)\n",
    "        # 16 x 16 x 16 x 16 -> 32 x 16 x 16 x 16\n",
    "        out_L = self.conv3(out_L)\n",
    "        out_L = self.relu(out_L)\n",
    "        # 32 x 16 x 16 x 16 -> 16 x 16 x 16 x 16\n",
    "        out_L = self.conv4(out_L)\n",
    "        # out_L = self.dropout(out_L)\n",
    "        # (16 x 16 x 16 x 16) + (16 x 16 x 16 x 16) -> 32 x 16 x 16 x 16\n",
    "        out = torch.cat((out_L, out_R), dim=1)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class RB3D(nn.Module):\n",
    "    def __init__(self, num_classes=10, keepfc=True):\n",
    "        super(RB3D, self).__init__()\n",
    "        # dimensions of the 3D image. Channels, Depth, Height, Width\n",
    "        self.C = 1\n",
    "        self.D = 32\n",
    "        self.H = 32\n",
    "        self.W = 32\n",
    "        self.keepfc = keepfc\n",
    "\n",
    "        self.conv1 = nn.Conv3d(self.C, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "        self.bottleneck_layers = nn.Sequential(*[Bottleneck(), Bottleneck(), Bottleneck(), Bottleneck()])\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((2, 2, 2))\n",
    "        if keepfc:\n",
    "            self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "        # self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1 x 32 x 32 x 32 -> 32 x 32 x 32 x 32\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        # 32 x 32 x 32 x 32 -> 32 x 16 x 16 x 16\n",
    "        x = self.maxpool(x)\n",
    "        # 32 x 16 x 16 x 16 -> 32 x 16 x 16 x 16\n",
    "        x = self.bottleneck_layers(x)\n",
    "        # 32 x 16 x 16 x 16 -> 32 x 2 x 2 x 2\n",
    "        x = self.avgpool(x)\n",
    "        # 32 x 2 x 2 x 2 -> 256\n",
    "        x = torch.flatten(x, 1)\n",
    "        # x = self.dropout(x)\n",
    "        if self.keepfc:\n",
    "            # 256 -> num_classes\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:10:23.774982Z",
     "start_time": "2024-03-14T05:10:23.758949Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# DSRF3D_v2\n",
    "class DSRF3D_v2(nn.Module):\n",
    "    def __init__(self, num_classes=10, keepfc=True):\n",
    "        super(DSRF3D_v2, self).__init__()\n",
    "        # dimensions of the 3D image. Channels, Depth, Height, Width\n",
    "        C = 1\n",
    "        D = 32\n",
    "        H = 32\n",
    "        W = 32\n",
    "        self.keepfc = keepfc\n",
    "\n",
    "        self.conv1 = nn.Conv3d(C, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv3d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv3d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "\n",
    "        if keepfc:\n",
    "            self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1 x 32 x 32 x 32 -> 32 x 32 x 32 x 32\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # 32 x 32 x 32 x 32 -> 32 x 32 x 32 x 32\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # 32 x 32 x 32 x 32 -> 32 x 16 x 16 x 16\n",
    "        x = F.max_pool3d(x, kernel_size=2, stride=2, padding=0)\n",
    "        # 32 x 16 x 16 x 16 -> 64 x 16 x 16 x 16\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # 64 x 16 x 16 x 16 -> 64 x 16 x 16 x 16\n",
    "        x = F.relu(self.conv4(x))\n",
    "        # 64 x 16 x 16 x 16 -> 64 x 8 x 8 x 8\n",
    "        x = F.max_pool3d(x, kernel_size=2, stride=2, padding=0)\n",
    "        # 64 x 8 x 8 x 8 -> 128 x 8 x 8 x 8\n",
    "        x = F.relu(self.conv5(x))\n",
    "        # 128 x 8 x 8 x 8 -> 128 x 8 x 8 x 8\n",
    "        x = F.relu(self.conv6(x))\n",
    "        # 128 x 8 x 8 x 8 -> 128 x 1 x 1 x 1\n",
    "        x = self.avgpool(x)\n",
    "        # 128 x 1 x 1 x 1 -> 128\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.keepfc:\n",
    "            # 128 -> num_classes\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:10:28.030459Z",
     "start_time": "2024-03-14T05:10:28.015315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# YOPO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv3d, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, **kwargs)\n",
    "        self.elu = nn.ELU(alpha=1.0)\n",
    "        self.bn = nn.BatchNorm3d(out_channels, eps=0.001, momentum=0.99)\n",
    "        # self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in_channels x ... -> out_channels x ...\n",
    "        x = self.conv(x)\n",
    "        # out_channels x ... -> out_channels x ...\n",
    "        x = self.elu(x)\n",
    "        # out_channels x ... -> out_channels x ...\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class YOPO(nn.Module):\n",
    "    def __init__(self, num_classes=10, keepfc=True):\n",
    "        super(YOPO, self).__init__()\n",
    "        # dimensions of the 3D image. Channels, Depth, Height, Width\n",
    "        C = 1\n",
    "        D = 32\n",
    "        H = 32\n",
    "        W = 32\n",
    "        # self.keepfc = keepfc\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "        # 1 x 32^3 -> 4 x 30^3\n",
    "        self.conv_1_1 = BasicConv3d(1, 4, kernel_size=3, padding='valid')\n",
    "        # 4 x 30^3 -> 5 x 28^3\n",
    "        self.conv_1_2 = BasicConv3d(4, 5, kernel_size=3, padding='valid')\n",
    "        # 5 x 28^3 -> 6 x 26^3\n",
    "        self.conv_1_3 = BasicConv3d(5, 6, kernel_size=3, padding='valid')\n",
    "        # 6 x 26^3 -> 7 x 24^3\n",
    "        self.conv_1_4 = BasicConv3d(6, 7, kernel_size=3, padding='valid')\n",
    "        # 7 x 24^3 -> 8 x 22^3\n",
    "        self.conv_1_5 = BasicConv3d(7, 8, kernel_size=3, padding='valid')\n",
    "        # 8 x 22^3 -> 9 x 20^3\n",
    "        self.conv_1_6 = BasicConv3d(8, 9, kernel_size=3, padding='valid')\n",
    "\n",
    "        # 1 x 32^3 -> 3 x 29^3\n",
    "        self.conv_2_1 = BasicConv3d(1, 3, kernel_size=4, padding='valid')\n",
    "        # 3 x 29^3 -> 4 x 26^3\n",
    "        self.conv_2_2 = BasicConv3d(3, 4, kernel_size=4, padding='valid')\n",
    "        # 4 x 26^3 -> 5 x 23^3\n",
    "        self.conv_2_3 = BasicConv3d(4, 5, kernel_size=4, padding='valid')\n",
    "        # 5 x 23^3 -> 6 x 20^3\n",
    "        self.conv_2_4 = BasicConv3d(5, 6, kernel_size=4, padding='valid')\n",
    "\n",
    "        # 1 x 32^3 -> 2 x 28^3\n",
    "        self.conv_3_1 = BasicConv3d(1, 2, kernel_size=5, padding='valid')\n",
    "        # 2 x 28^3 -> 3 x 24^3\n",
    "        self.conv_3_2 = BasicConv3d(2, 3, kernel_size=5, padding='valid')\n",
    "        # 3 x 24^3 -> 4 x 20^3\n",
    "        self.conv_3_3 = BasicConv3d(3, 4, kernel_size=5, padding='valid')\n",
    "\n",
    "        # 1 x 32^3 -> 1 x 26^3\n",
    "        self.conv_4_1 = BasicConv3d(1, 1, kernel_size=7, padding='valid')\n",
    "        # 1 x 26^3 -> 2 x 20^3\n",
    "        self.conv_4_2 = BasicConv3d(1, 2, kernel_size=7, padding='valid')\n",
    "\n",
    "        # (9+6+4+2)=21 x 20^3 -> 10 x 18^3\n",
    "        self.conv_5_1 = BasicConv3d(21, 10, kernel_size=3, padding='valid')\n",
    "        # 10 x 18^3 -> 11 x 16^3\n",
    "        self.conv_5_2 = BasicConv3d(10, 11, kernel_size=3, padding='valid')\n",
    "        # 11 x 16^3 -> 12 x 14^3\n",
    "        self.conv_5_3 = BasicConv3d(11, 12, kernel_size=3, padding='valid')\n",
    "        # 12 x 14^3 -> 13 x 12^3\n",
    "        self.conv_5_4 = BasicConv3d(12, 13, kernel_size=3, padding='valid')\n",
    "        # 13 x 12^3 -> 14 x 10^3\n",
    "        self.conv_5_5 = BasicConv3d(13, 14, kernel_size=3, padding='valid')\n",
    "        # 14 x 10^3 -> 15 x 8^3\n",
    "        self.conv_5_6 = BasicConv3d(14, 15, kernel_size=3, padding='valid')\n",
    "        # 15 x 8^3 -> 16 x 6^3\n",
    "        self.conv_5_7 = BasicConv3d(15, 16, kernel_size=3, padding='valid')\n",
    "        # 16 x 6^3 -> 17 x 4^3\n",
    "        self.conv_5_8 = BasicConv3d(16, 17, kernel_size=3, padding='valid')\n",
    "        # 17 x 4^3 -> 18 x 2^3\n",
    "        self.conv_5_9 = BasicConv3d(17, 18, kernel_size=3, padding='valid')\n",
    "\n",
    "        # (9+6+4+2)=21 x 20^3 -> 7 x 17^3\n",
    "        self.conv_6_1 = BasicConv3d(21, 7, kernel_size=4, padding='valid')\n",
    "        # 7 x 17^3 -> 8 x 14^3\n",
    "        self.conv_6_2 = BasicConv3d(7, 8, kernel_size=4, padding='valid')\n",
    "        # 8 x 14^3 -> 9 x 11^3\n",
    "        self.conv_6_3 = BasicConv3d(8, 9, kernel_size=4, padding='valid')\n",
    "        # 9 x 11^3 -> 10 x 8^3\n",
    "        self.conv_6_4 = BasicConv3d(9, 10, kernel_size=4, padding='valid')\n",
    "        # 10 x 8^3 -> 11 x 5^3\n",
    "        self.conv_6_5 = BasicConv3d(10, 11, kernel_size=4, padding='valid')\n",
    "        # 11 x 5^3 -> 12 x 2^3\n",
    "        self.conv_6_6 = BasicConv3d(11, 12, kernel_size=4, padding='valid')\n",
    "\n",
    "        # (9+6+4+2)=21 x 20^3 -> 5 x 16^3\n",
    "        self.conv_7_1 = BasicConv3d(21, 5, kernel_size=5, padding='valid')\n",
    "        # 5 x 16^3 -> 6 x 12^3\n",
    "        self.conv_7_2 = BasicConv3d(5, 6, kernel_size=5, padding='valid')\n",
    "        # 6 x 12^3 -> 7 x 8^3\n",
    "        self.conv_7_3 = BasicConv3d(6, 7, kernel_size=5, padding='valid')\n",
    "        # 7 x 8^3 -> 8 x 4^3\n",
    "        self.conv_7_4 = BasicConv3d(7, 8, kernel_size=5, padding='valid')\n",
    "\n",
    "        # (9+6+4+2)=21 x 20^3 -> 3 x 14^3\n",
    "        self.conv_8_1 = BasicConv3d(21, 3, kernel_size=6, padding='valid')\n",
    "        # 3 x 14^3 -> 4 x 8^3\n",
    "        self.conv_8_2 = BasicConv3d(3, 4, kernel_size=6, padding='valid')\n",
    "        # 4 x 8^3-> 5 x 2^3\n",
    "        self.conv_8_3 = BasicConv3d(4, 5, kernel_size=6, padding='valid')\n",
    "\n",
    "        # self.elu = nn.ELU(alpha=1.0)\n",
    "        self.bn1 = nn.BatchNorm1d(290, eps=0.001, momentum=0.99)\n",
    "        self.linear1 = nn.Linear(290, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256, eps=0.001, momentum=0.99)\n",
    "        self.linear2 = nn.Linear(546, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128, eps=0.001, momentum=0.99)\n",
    "        self.linear3 = nn.Linear(674, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm3d) or isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1 x 32^3 -> 4 x 30^3\n",
    "        c_1 = self.conv_1_1(x)\n",
    "        # 4 x 30^3 -> 4\n",
    "        m_1_1 = torch.flatten(self.avgpool(c_1), 1)\n",
    "        # 4 x 30^3 -> 5 x 28^3\n",
    "        c_1 = self.conv_1_2(c_1)\n",
    "        # 5 x 28^3 -> 5\n",
    "        m_1_2 = torch.flatten(self.avgpool(c_1), 1)\n",
    "        # 5 x 28^3 -> 6 x 26^3\n",
    "        c_1 = self.conv_1_3(c_1)\n",
    "        # 6 x 26^3 -> 6\n",
    "        m_1_3 = torch.flatten(self.avgpool(c_1), 1)\n",
    "        # 6 x 26^3 -> 7 x 24^3\n",
    "        c_1 = self.conv_1_4(c_1)\n",
    "        # 7 x 24^3 -> 7\n",
    "        m_1_4 = torch.flatten(self.avgpool(c_1), 1)\n",
    "        # 7 x 24^3 -> 8 x 22^3\n",
    "        c_1 = self.conv_1_5(c_1)\n",
    "        # 8 x 22^3 -> 8\n",
    "        m_1_5 = torch.flatten(self.avgpool(c_1), 1)\n",
    "        # 8 x 22^3 -> 9 x 20^3\n",
    "        c_1 = self.conv_1_6(c_1)\n",
    "        # 9 x 20^3-> 9\n",
    "        m_1_6 = torch.flatten(self.avgpool(c_1), 1)\n",
    "\n",
    "        # 1 x 32^3 -> 3 x 29^3\n",
    "        c_2 = self.conv_2_1(x)\n",
    "        # 3 x 29^3 -> 3\n",
    "        m_2_1 = torch.flatten(self.avgpool(c_2), 1)\n",
    "        # 3 x 29^3 -> 4 x 26^3\n",
    "        c_2 = self.conv_2_2(c_2)\n",
    "        # 4 x 26^3 -> 4\n",
    "        m_2_2 = torch.flatten(self.avgpool(c_2), 1)\n",
    "        # 4 x 26^3 -> 5 x 23^3\n",
    "        c_2 = self.conv_2_3(c_2)\n",
    "        # 5 x 23^3 -> 5\n",
    "        m_2_3 = torch.flatten(self.avgpool(c_2), 1)\n",
    "        # 5 x 23^3 -> 6 x 20^3\n",
    "        c_2 = self.conv_2_4(c_2)\n",
    "        # 6 x 20^3 -> 6\n",
    "        m_2_4 = torch.flatten(self.avgpool(c_2), 1)\n",
    "\n",
    "        # 1 x 32^3 -> 2 x 28^3\n",
    "        c_3 = self.conv_3_1(x)\n",
    "        # 2 x 28^3 -> 2\n",
    "        m_3_1 = torch.flatten(self.avgpool(c_3), 1)\n",
    "        # 2 x 28^3 -> 3 x 24^3\n",
    "        c_3 = self.conv_3_2(c_3)\n",
    "        # 3 x 16^3 -> 3\n",
    "        m_3_2 = torch.flatten(self.avgpool(c_3), 1)\n",
    "        # 3 x 24^3 -> 4 x 20^3\n",
    "        c_3 = self.conv_3_3(c_3)\n",
    "        # 4 x 20^3 -> 4\n",
    "        m_3_3 = torch.flatten(self.avgpool(c_3), 1)\n",
    "\n",
    "        # 1 x 32^3 -> 1 x 26^3\n",
    "        c_4 = self.conv_4_1(x)\n",
    "        # 1 x 26^3 -> 1\n",
    "        m_4_1 = torch.flatten(self.avgpool(c_4), 1)\n",
    "        # 1 x 26^3 -> 2 x 20^3\n",
    "        c_4 = self.conv_4_2(c_4)\n",
    "        # 2 x 20^3 -> 2\n",
    "        m_4_2 = torch.flatten(self.avgpool(c_4), 1)\n",
    "\n",
    "        # (9+6+4+2)=21 x 20^3\n",
    "        x = torch.cat((c_1, c_2, c_3, c_4), dim=1)\n",
    "\n",
    "        # 21 x 20^3 -> 10 x 18^3\n",
    "        c_5 = self.conv_5_1(x)\n",
    "        # 10 x 18^3 -> 10\n",
    "        m_5_1 = torch.flatten(self.avgpool(c_5), 1)\n",
    "        # 10 x 18^3 -> 11 x 16^3\n",
    "        c_5 = self.conv_5_2(c_5)\n",
    "        # 11 x 16^3 -> 11\n",
    "        m_5_2 = torch.flatten(self.avgpool(c_5), 1)\n",
    "        # 11 x 16^3 -> 12 x 14^3\n",
    "        c_5 = self.conv_5_3(c_5)\n",
    "        # 12 x 14^3 -> 12\n",
    "        m_5_3 = torch.flatten(self.avgpool(c_5), 1)\n",
    "        # 12 x 14^3 -> 13 x 12^3\n",
    "        c_5 = self.conv_5_4(c_5)\n",
    "        # 13 x 12^3 -> 13\n",
    "        m_5_4 = torch.flatten(self.avgpool(c_5), 1)\n",
    "        # 13 x 12^3 -> 14 x 10^3\n",
    "        c_5 = self.conv_5_5(c_5)\n",
    "        # 14 x 10^3 -> 14\n",
    "        m_5_5 = torch.flatten(self.avgpool(c_5), 1)\n",
    "        # 14 x 10^3 -> 15 x 8^3\n",
    "        c_5 = self.conv_5_6(c_5)\n",
    "        # 15 x 8^3 -> 15\n",
    "        m_5_6 = torch.flatten(self.avgpool(c_5), 1)\n",
    "        # 15 x 8^3 -> 16 x 6^3\n",
    "        c_5 = self.conv_5_7(c_5)\n",
    "        # 16 x 6^3 -> 16\n",
    "        m_5_7 = torch.flatten(self.avgpool(c_5), 1)\n",
    "        # 16 x 6^3 -> 17 x 4^3\n",
    "        c_5 = self.conv_5_8(c_5)\n",
    "        # 17 x 4^3 -> 17\n",
    "        m_5_8 = torch.flatten(self.avgpool(c_5), 1)\n",
    "        # 17 x 4^3 -> 18 x 2^3\n",
    "        c_5 = self.conv_5_9(c_5)\n",
    "        # 18 x 2^3 -> 18\n",
    "        m_5_9 = torch.flatten(self.avgpool(c_5), 1)\n",
    "\n",
    "        # 21 x 20^3 -> 7 x 17^3\n",
    "        c_6 = self.conv_6_1(x)\n",
    "        # 7 x 17^3 -> 7\n",
    "        m_6_1 = torch.flatten(self.avgpool(c_6), 1)\n",
    "        # 7 x 17^3 -> 8 x 14^3\n",
    "        c_6 = self.conv_6_2(c_6)\n",
    "        # 8 x 14^3 -> 8\n",
    "        m_6_2 = torch.flatten(self.avgpool(c_6), 1)\n",
    "        # 8 x 14^3 -> 9 x 11^3\n",
    "        c_6 = self.conv_6_3(c_6)\n",
    "        # 9 x 11^3 -> 9\n",
    "        m_6_3 = torch.flatten(self.avgpool(c_6), 1)\n",
    "        # 9 x 11^3-> 10 x 8^3\n",
    "        c_6 = self.conv_6_4(c_6)\n",
    "        # 10 x 8^3 -> 10\n",
    "        m_6_4 = torch.flatten(self.avgpool(c_6), 1)\n",
    "        # 10 x 8^3-> 11 x 5^3\n",
    "        c_6 = self.conv_6_5(c_6)\n",
    "        # 11 x 5^3 -> 11\n",
    "        m_6_5 = torch.flatten(self.avgpool(c_6), 1)\n",
    "        # 11 x 5^3-> 12 x 2^3\n",
    "        c_6 = self.conv_6_6(c_6)\n",
    "        # 12 x 2^3 -> 12\n",
    "        m_6_6 = torch.flatten(self.avgpool(c_6), 1)\n",
    "\n",
    "        # 21 x 20^3 -> 5 x 16^3\n",
    "        c_7 = self.conv_7_1(x)\n",
    "        # 5 x 16^3 -> 5\n",
    "        m_7_1 = torch.flatten(self.avgpool(c_7), 1)\n",
    "        # 5 x 16^3 -> 6 x 12^3\n",
    "        c_7 = self.conv_7_2(c_7)\n",
    "        # 6 x 12^3 -> 6\n",
    "        m_7_2 = torch.flatten(self.avgpool(c_7), 1)\n",
    "        # 6 x 12^3 -> 7 x 8^3\n",
    "        c_7 = self.conv_7_3(c_7)\n",
    "        # 7 x 8^3 -> 7\n",
    "        m_7_3 = torch.flatten(self.avgpool(c_7), 1)\n",
    "        # 7 x 8^3 -> 8 x 4^3\n",
    "        c_7 = self.conv_7_4(c_7)\n",
    "        # 8 x 4^3 -> 8\n",
    "        m_7_4 = torch.flatten(self.avgpool(c_7), 1)\n",
    "\n",
    "        # 21 x 20^3 -> 3 x 14^3\n",
    "        c_8 = self.conv_8_1(x)\n",
    "        # 3 x 14^3 -> 3\n",
    "        m_8_1 = torch.flatten(self.avgpool(c_8), 1)\n",
    "        # 3 x 14^3 -> 4 x 8^3\n",
    "        c_8 = self.conv_8_2(c_8)\n",
    "        # 4 x 8^3 -> 4\n",
    "        m_8_2 = torch.flatten(self.avgpool(c_8), 1)\n",
    "        # 4 x 8^3 -> 5 x 2^3\n",
    "        c_8 = self.conv_8_3(c_8)\n",
    "        # 5 x 2^3 -> 5\n",
    "        m_8_3 = torch.flatten(self.avgpool(c_8), 1)\n",
    "\n",
    "        # ((4+5+6+7+8+9)=39 + (3+4+5+6)=18 + (2+3+4)=9 + (1+2)=3 +\n",
    "        # (10+11+12+13+14+15+16+17+18)=126 + (7+8+9+10+11+12)=57 + (5+6+7+8)=26 + (3+4+5)=12)=290\n",
    "        m = torch.cat(\n",
    "            (m_1_1, m_1_2, m_1_3, m_1_4, m_1_5, m_1_6,\n",
    "             m_2_1, m_2_2, m_2_3, m_2_4,\n",
    "             m_3_1, m_3_2, m_3_3,\n",
    "             m_4_1, m_4_2,\n",
    "             m_5_1, m_5_2, m_5_3, m_5_4, m_5_5, m_5_6, m_5_7, m_5_8, m_5_9,\n",
    "             m_6_1, m_6_2, m_6_3, m_6_4, m_6_5, m_6_6,\n",
    "             m_7_1, m_7_2, m_7_3, m_7_4,\n",
    "             m_8_1, m_8_2, m_8_3),\n",
    "            dim=1)\n",
    "\n",
    "        fc1 = self.bn1(m)\n",
    "        # 290 -> 256\n",
    "        m = self.linear1(fc1)\n",
    "        m = F.elu(m)\n",
    "        fc2 = self.bn2(m)\n",
    "        # 290+256=546\n",
    "        fc2 = torch.cat((fc1, fc2), dim=1)\n",
    "        # 546 -> 128\n",
    "        m = self.linear2(fc2)\n",
    "        m = F.elu(m)\n",
    "        fc3 = self.bn3(m)\n",
    "        # 546+128=674\n",
    "        fc3 = torch.cat((fc2, fc3), dim=1)\n",
    "        # 674 -> num_classes\n",
    "        m = self.linear3(fc3)\n",
    "\n",
    "        return m"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:10:28.913557Z",
     "start_time": "2024-03-14T05:10:28.813419Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.2 Train and Val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# https://github.com/Shadowalker1995/MOCO-Subtomograms/blob/master/main_moco.py\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Train for one epoch\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    # Display metrics\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':6.2f')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    print_freq = 10\n",
    "    end = time.time()\n",
    "    # start to train\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if gpu is not None:\n",
    "            images = images.cuda(gpu, non_blocking=True)\n",
    "            target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        # acc1/acc5 are (K+1)-way contrast classifier accuracy\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    # switch to evaluate mode\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':6.2f')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Val: \")\n",
    "    model.eval()\n",
    "    print_freq = 10\n",
    "    end = time.time()\n",
    "    # start evaluation\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "            if gpu is not None:\n",
    "                images = images.cuda(gpu, non_blocking=True)\n",
    "                target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            if i % print_freq == 0:\n",
    "                progress.display(i)\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint/model_best.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'checkpoint/model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(lr,schedule,cos,optimizer, epoch,epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    if cos:  # cosine lr schedule\n",
    "        lr *= 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    else:  # stepwise lr schedule\n",
    "        for milestone in schedule:\n",
    "            lr *= 0.1 if epoch >= milestone else 1.\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:42:00.076536Z",
     "start_time": "2024-03-14T05:42:00.054947Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the model, you can also customize the model.\n",
    "model_dictionary = {'RB3D': RB3D, 'DSRF3D_v2': DSRF3D_v2,\n",
    "                    'YOPO': YOPO}\n",
    "# Training parameters\n",
    "arch = 'RB3D'\n",
    "lr = 0.003\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "epochs = 600\n",
    "cos = False # cosine lr schedule\n",
    "schedule = [300,400,500]  # stepwise lr schedule\n",
    "gpu = 1 # choose gpu to use\n",
    "\n",
    "# Adjust num_classes based on the data.\n",
    "model = model_dictionary[arch](num_classes=10)\n",
    "model.cuda(gpu)\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "best_loss = 10\n",
    "for epoch in range(epochs):\n",
    "    adjust_learning_rate(lr,schedule,cos,optimizer, epoch,epochs)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        avg_loss = validate(val_loader, model, criterion, epoch)\n",
    "        # save the best model\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, is_best=False,\n",
    "                filename='checkpoint/arch-{}_bs{}_lr{}_best.pth.tar'.format(\n",
    "                    arch, batch_size, lr))\n",
    "        # save the last model\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': arch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best=False,\n",
    "            filename='checkpoint/arch-{}_bs{}_lr{}_last.pth.tar'.format(\n",
    "                arch, batch_size, lr))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.3 Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_dictionary = {'RB3D': RB3D, 'DSRF3D_v2': DSRF3D_v2,\n",
    "                    'YOPO': YOPO}\n",
    "# test parameters\n",
    "arch = 'RB3D'\n",
    "gpu = 1 # choose gpu to use\n",
    "checkpoint_path = 'checkpoint/arch-RB3D_bs32_lr0.003_best.pth.tar'\n",
    "\n",
    "# Adjust num_classes based on the data.\n",
    "model = model_dictionary[arch](num_classes=10)\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "state_dict = checkpoint['state_dict']\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.cuda(gpu)\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "validate(test_loader,model,criterion)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
